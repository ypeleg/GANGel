{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "sys.path.insert(0,'../..')\n",
    "\n",
    "from AutoGAN import GAN\n",
    "from AutoGAN.schemes.CycleGAN_TrainingScheme import CycleGAN_TrainingScheme\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import UpSampling2D, LeakyReLU, Lambda, Add, Multiply, Activation, Conv2DTranspose\n",
    "from keras.layers import Cropping2D, ZeroPadding2D, Flatten, Subtract, Input, add, multiply\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from skimage.transform import resize\n",
    "import glob\n",
    "from random import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "config.gpu_options.visible_device_list = \"1\"\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "def build_generator(gf, size):\n",
    "    \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "    def conv2d(layer_input, filters, f_size=4):\n",
    "        \"\"\"Layers used during downsampling\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        d = BatchNormalization()(d)\n",
    "        return d\n",
    "\n",
    "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "        \"\"\"Layers used during upsampling\"\"\"\n",
    "        u = UpSampling2D(size=2)(layer_input)\n",
    "        u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "        if dropout_rate:\n",
    "            u = Dropout(dropout_rate)(u)\n",
    "        u = BatchNormalization()(u)\n",
    "        u = Concatenate()([u, skip_input])\n",
    "        return u\n",
    "\n",
    "    # Image input\n",
    "    d0 = Input(shape=size)\n",
    "\n",
    "    # Downsampling\n",
    "    d1 = conv2d(d0, gf)\n",
    "    d2 = conv2d(d1, gf*2)\n",
    "    d3 = conv2d(d2, gf*4)\n",
    "    d4 = conv2d(d3, gf*8)\n",
    "    d5 = conv2d(d4, gf*16)\n",
    "\n",
    "    # Upsampling\n",
    "    u0 = deconv2d(d5, d4, gf*16)\n",
    "    u1 = deconv2d(u0, d3, gf*4)\n",
    "    u2 = deconv2d(u1, d2, gf*2)\n",
    "    u3 = deconv2d(u2, d1, gf)\n",
    "\n",
    "    u4 = UpSampling2D(size=2)(u3)\n",
    "    output_img = Conv2D(3, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
    "\n",
    "    return Model(d0, output_img)\n",
    "\n",
    "def build_discriminator(df, size):\n",
    "\n",
    "    def d_layer(layer_input, filters, f_size=4, normalization=True):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if normalization:\n",
    "            d = BatchNormalization()(d)\n",
    "        return d\n",
    "\n",
    "    img = Input(shape=size)\n",
    "\n",
    "    d1 = d_layer(img, df, normalization=False)\n",
    "    d2 = d_layer(d1, df*2)\n",
    "    d3 = d_layer(d2, df*4)\n",
    "    d4 = d_layer(d3, df*8)\n",
    "    d5 = d_layer(d4, df*16)\n",
    "\n",
    "    validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d5)\n",
    "\n",
    "    return Model(img, validity)\n",
    "\n",
    "\n",
    "def load_data(dataset):\n",
    "    filelist_A = glob.glob('./%s/trainA/*.jpg' % dataset)\n",
    "    shuffle(filelist_A)\n",
    "    A = np.array([plt.imread(file) for file in filelist_A])\n",
    "    print(A.shape)\n",
    "    A = (2. * A/255.) - 1.\n",
    "    \n",
    "    filelist_B = glob.glob('./%s/trainB/*.jpg' % dataset)\n",
    "    shuffle(filelist_B)\n",
    "    B = np.array([plt.imread(file) for file in filelist_B if plt.imread(file).shape[-1] == 3 ])\n",
    "    print(B.shape)\n",
    "    B = (2. * B/255.) - 1.\n",
    "    return A, B\n",
    "\n",
    "def load_data_test(dataset):\n",
    "    filelist_A = glob.glob('./%s/testA/*.jpg' % dataset)\n",
    "    shuffle(filelist_A)\n",
    "    A = np.array([plt.imread(file) for file in filelist_A])\n",
    "    print(A.shape)\n",
    "    A = (2. * A/255.) - 1.\n",
    "    \n",
    "    filelist_B = glob.glob('./%s/testB/*.jpg' % dataset)\n",
    "    shuffle(filelist_B)\n",
    "    B = np.array([plt.imread(file) for file in filelist_B])\n",
    "    print(B.shape)\n",
    "    B = (2. * B/255.) - 1.\n",
    "    return A, B\n",
    "\n",
    "\n",
    "\n",
    "class save_images(keras.callbacks.Callback):\n",
    "    def __init__(self, model, A, B, freq, dataset):\n",
    "        super(save_images, self).__init__()\n",
    "        try:\n",
    "            import os\n",
    "            os.makedirs('images/%s' % dataset)\n",
    "        except:\n",
    "            pass\n",
    "        self.full_model = model\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.epoch = 0\n",
    "        self.freq = freq\n",
    "        self.dataset = dataset\n",
    "    def sample_images(self, epoch, batch_i, A=None, B=None):\n",
    "        r, c = 2, 3\n",
    "\n",
    "        # Demo (for GIF)\n",
    "        if A is None:\n",
    "            if 'apple2orange' in self.dataset:\n",
    "                A = np.array([plt.imread('./apple2orange/testA/n07740461_1541.jpg','jpg')])\n",
    "            else:\n",
    "                A = np.array([plt.imread('./horse2zebra/testA/n02381460_1300.jpg','jpg')])\n",
    "            A = (2. * A/255.) - 1.\n",
    "        if B is None:\n",
    "            if 'apple2orange' in self.dataset:\n",
    "                B = np.array([plt.imread('./apple2orange/testB/n07749192_4241.jpg','jpg')])\n",
    "            else:\n",
    "                B = np.array([plt.imread('./horse2zebra/testB/n02391049_9960.jpg','jpg')])\n",
    "            B = (2. * B/255.) - 1.\n",
    "\n",
    "        # Translate images to the other domain\n",
    "        fake_A = self.full_model.generator_model()[0].predict(B)\n",
    "        fake_B = self.full_model.generator_model()[1].predict(A)\n",
    "        # Translate back to original domain\n",
    "        reconstr_A = self.full_model.generator_model()[0].predict(fake_B)\n",
    "        reconstr_B = self.full_model.generator_model()[1].predict(fake_A)\n",
    "\n",
    "        gen_imgs = np.concatenate([A, fake_B, reconstr_A, B, fake_A, reconstr_B])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        #gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c,figsize=(10,10))\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow((gen_imgs[cnt]+1.)/2.)\n",
    "                axs[i, j].set_title(titles[j])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset, epoch, batch_i))\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch = epoch\n",
    "        #print('started epoch %d' % epoch)\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pass #print(logs)\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if batch % self.freq == 0:\n",
    "            self.sample_images(self.epoch, batch)\n",
    "            #print('sampled data at epoch %d , batch %d' % (self.epoch, batch))\n",
    "    def on_train_end(self, logs=None):\n",
    "        for i in range(1, self.A.shape[0]):\n",
    "            try:\n",
    "                self.sample_images(self.epoch+1, i-1, self.A[i-1:i], self.B[i-1:i])\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "class pretrain_model(keras.callbacks.Callback):\n",
    "    def __init__(self, my_model, x, y, epochs, batch_size, loss, metrics, optimizer):        \n",
    "        self.my_model = my_model\n",
    "        self.x, self.y = x, y\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        self.optimizer = optimizer\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.my_model.compile(loss=self.loss, metrics=self.metrics, optimizer=self.optimizer)\n",
    "        self.my_model.fit(self.x, self.y, epochs=self.epochs, batch_size=self.batch_size, verbose=1, shuffle=True, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995, 256, 256, 3)\n",
      "(1019, 256, 256, 3)\n",
      "(266, 256, 256, 3)\n",
      "(248, 256, 256, 3)\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elad/anaconda2/envs/TF-1.12/lib/python2.7/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 190s 190ms/step - model_4_fake_0_loss: 0.3315 - generator_model_loss: 8.6837 - model_2_reconstruct_b_0_loss: 0.3426 - model_3_valid_a_0_loss: 0.5883 - model_2_id_b_0_loss: 0.3902 - model_4_valid_b_0_loss: 0.6963 - discriminator_model_loss: 1.5144 - model_1_id_a_0_loss: 0.3743 - model_3_fake_0_loss: 0.3373 - model_1_reconstruct_a_0_loss: 0.3209 - model_3_real_0_loss: 0.4132 - model_4_real_0_loss: 0.4323\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 175s 175ms/step - model_4_fake_0_loss: 0.1722 - generator_model_loss: 6.5231 - model_2_reconstruct_b_0_loss: 0.2543 - model_3_valid_a_0_loss: 0.4787 - model_2_id_b_0_loss: 0.2572 - model_4_valid_b_0_loss: 0.5669 - discriminator_model_loss: 0.8309 - model_1_id_a_0_loss: 0.2408 - model_3_fake_0_loss: 0.1940 - model_1_reconstruct_a_0_loss: 0.2437 - model_3_real_0_loss: 0.2452 - model_4_real_0_loss: 0.2194\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 177s 177ms/step - model_4_fake_0_loss: 0.1535 - generator_model_loss: 6.1577 - model_2_reconstruct_b_0_loss: 0.2329 - model_3_valid_a_0_loss: 0.4928 - model_2_id_b_0_loss: 0.2328 - model_4_valid_b_0_loss: 0.5841 - discriminator_model_loss: 0.7416 - model_1_id_a_0_loss: 0.2288 - model_3_fake_0_loss: 0.1801 - model_1_reconstruct_a_0_loss: 0.2290 - model_3_real_0_loss: 0.2231 - model_4_real_0_loss: 0.1850\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 177s 177ms/step - model_4_fake_0_loss: 0.1431 - generator_model_loss: 6.0128 - model_2_reconstruct_b_0_loss: 0.2204 - model_3_valid_a_0_loss: 0.5416 - model_2_id_b_0_loss: 0.2210 - model_4_valid_b_0_loss: 0.6200 - discriminator_model_loss: 0.6634 - model_1_id_a_0_loss: 0.2211 - model_3_fake_0_loss: 0.1534 - model_1_reconstruct_a_0_loss: 0.2205 - model_3_real_0_loss: 0.2007 - model_4_real_0_loss: 0.1662\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 177s 177ms/step - model_4_fake_0_loss: 0.1259 - generator_model_loss: 5.8419 - model_2_reconstruct_b_0_loss: 0.2104 - model_3_valid_a_0_loss: 0.5883 - model_2_id_b_0_loss: 0.2130 - model_4_valid_b_0_loss: 0.6784 - discriminator_model_loss: 0.6067 - model_1_id_a_0_loss: 0.2108 - model_3_fake_0_loss: 0.1410 - model_1_reconstruct_a_0_loss: 0.2047 - model_3_real_0_loss: 0.1849 - model_4_real_0_loss: 0.1549\n"
     ]
    }
   ],
   "source": [
    "A, B = load_data('apple2orange')\n",
    "A_test, B_test = load_data_test('apple2orange')\n",
    "\n",
    "def cyclegan(image_A, image_B):\n",
    "    model = GAN(generator=[build_generator(32, image_A.shape),build_generator(32, image_B.shape)], \n",
    "                discriminator=[build_discriminator(32, image_A.shape),build_discriminator(32, image_B.shape)])\n",
    "    optimizer = keras.optimizers.Adam(0.0002, 0.5)\n",
    "    optimizerD = keras.optimizers.Adam(0.0001, 0.5)\n",
    "    try:\n",
    "        shutil.rmtree('./images/apple2orange_cyclegan')\n",
    "    except:\n",
    "        pass\n",
    "    discriminator_kwargs = {'loss':'mse', 'optimizer': optimizerD}\n",
    "    generator_kwargs = {'optimizer': optimizer,\n",
    "                        'translation_weight':1, 'cycle_weight':10, 'identity_weight':1,\n",
    "                        'translation_loss':'mse', 'cycle_loss':'mae', 'identity_loss':'mae'}\n",
    "    model.compile(training_scheme=CycleGAN_TrainingScheme(),\n",
    "                  generator_kwargs=generator_kwargs, discriminator_kwargs=discriminator_kwargs)\n",
    "    return model\n",
    "\n",
    "model = cyclegan(A[0], B[0])\n",
    "#model.summary(True)\n",
    "%matplotlib inline\n",
    "model.fit(x=A, y=B, epochs=5, steps_per_epoch=1000, batch_size=1,\n",
    "          generator_callbacks=[save_images(model, A_test, B_test, 100,'apple2orange_cyclegan')], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF 1.12 Keras 2.2.4",
   "language": "python",
   "name": "tf-1.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
